{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPWKpveZZk3QCKvoJ2berCa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmmanuelKiriinya/AfyaJamii/blob/main/maternal_health_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q langchain\n",
        "!pip install langchain-community langchain-groq faiss-cpu duckduckgo-search gtts googletrans speechrecognition pyttsx3 pydub transformers sentence-transformers ddgs"
      ],
      "metadata": {
        "id": "WMrq1YxlmvB0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea3a9129-86cc-4f70-90f7-7c5d4880a256"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Using cached langchain_community-0.3.30-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-groq\n",
            "  Using cached langchain_groq-0.3.8-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting faiss-cpu\n",
            "  Using cached faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting duckduckgo-search\n",
            "  Using cached duckduckgo_search-8.1.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gtts\n",
            "  Using cached gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting googletrans\n",
            "  Downloading googletrans-4.0.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting speechrecognition\n",
            "  Using cached speechrecognition-3.14.3-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting pyttsx3\n",
            "  Downloading pyttsx3-2.99-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (0.25.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Collecting ddgs\n",
            "  Downloading ddgs-9.6.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.76)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.43)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.28)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Collecting groq<1,>=0.30.0 (from langchain-groq)\n",
            "  Using cached groq-0.32.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from duckduckgo-search) (8.2.1)\n",
            "Collecting primp>=0.15.0 (from duckduckgo-search)\n",
            "  Using cached primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from duckduckgo-search) (5.4.0)\n",
            "Collecting click>=8.1.8 (from duckduckgo-search)\n",
            "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: httpx>=0.27.2 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]>=0.27.2->googletrans) (0.28.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from speechrecognition) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Collecting lxml>=5.3.0 (from duckduckgo-search)\n",
            "  Downloading lxml-6.0.2-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (2.11.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (0.16.0)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.1.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.3.0)\n",
            "Collecting socksio==1.* (from httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
            "  Downloading socksio-1.0.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.11)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (1.33)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.1.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (2.33.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Downloading langchain_community-0.3.30-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-0.3.8-py3-none-any.whl (16 kB)\n",
            "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading duckduckgo_search-8.1.1-py3-none-any.whl (18 kB)\n",
            "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Downloading googletrans-4.0.2-py3-none-any.whl (18 kB)\n",
            "Downloading speechrecognition-3.14.3-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyttsx3-2.99-py3-none-any.whl (32 kB)\n",
            "Downloading ddgs-9.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading groq-0.32.0-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading socksio-1.0.0-py3-none-any.whl (12 kB)\n",
            "Downloading lxml-6.0.2-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m140.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m123.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: pyttsx3, speechrecognition, socksio, requests, primp, mypy-extensions, marshmallow, lxml, faiss-cpu, click, typing-inspect, gtts, duckduckgo-search, groq, dataclasses-json, googletrans, ddgs, langchain-groq, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 5.4.0\n",
            "    Uninstalling lxml-5.4.0:\n",
            "      Successfully uninstalled lxml-5.4.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.2.1\n",
            "    Uninstalling click-8.2.1:\n",
            "      Successfully uninstalled click-8.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed click-8.1.8 dataclasses-json-0.6.7 ddgs-9.6.0 duckduckgo-search-8.1.1 faiss-cpu-1.12.0 googletrans-4.0.2 groq-0.32.0 gtts-2.5.4 langchain-community-0.3.30 langchain-groq-0.3.8 lxml-6.0.2 marshmallow-3.26.1 mypy-extensions-1.1.0 primp-0.15.0 pyttsx3-2.99 requests-2.32.5 socksio-1.0.0 speechrecognition-3.14.3 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import speech_recognition as sr\n",
        "# from gtts import gTTS\n",
        "# import io\n",
        "# from googletrans import Translator\n",
        "# from langchain_groq import ChatGroq\n",
        "# from langchain_community.vectorstores import FAISS\n",
        "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "# from langchain_community.document_loaders import WebBaseLoader\n",
        "# from langchain_community.tools import DuckDuckGoSearchRun\n",
        "# from duckduckgo_search import DDGS\n",
        "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# from langchain.memory import ConversationBufferMemory\n",
        "# from langchain.chains import ConversationalRetrievalChain\n",
        "# from langchain.schema import Document\n",
        "# from langchain.prompts import PromptTemplate\n",
        "# import requests\n",
        "# from pydub import AudioSegment\n",
        "# from pydub.playback import play\n",
        "# import base64\n",
        "# from IPython.display import Audio, display\n",
        "# from google.colab import userdata\n",
        "\n",
        "# os.environ[\"GROQ_API_KEY\"] = userdata.get('api_key')\n",
        "\n",
        "# class MaternalHealthRAG:\n",
        "#     def __init__(self):\n",
        "#         # Initialize components\n",
        "#         self.llm = ChatGroq(\n",
        "#             model_name=\"llama-3.1-8b-instant\",\n",
        "#             temperature=0.3\n",
        "#         )\n",
        "\n",
        "#         # Initialize embeddings\n",
        "#         self.embeddings = HuggingFaceEmbeddings(\n",
        "#             model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "#         )\n",
        "\n",
        "#         # Initialize vector store\n",
        "#         self.vector_store = None\n",
        "#         self.retriever = None\n",
        "\n",
        "#         # Initialize memory\n",
        "#         self.memory = ConversationBufferMemory(\n",
        "#             memory_key=\"chat_history\",\n",
        "#             return_messages=True,\n",
        "#             output_key='answer'\n",
        "#         )\n",
        "\n",
        "#         # Initialize tools\n",
        "#         self.search = DuckDuckGoSearchRun()\n",
        "#         self.translator = Translator()\n",
        "\n",
        "#         # Initialize speech recognition\n",
        "#         self.recognizer = sr.Recognizer()\n",
        "\n",
        "#         # Set up prompt template for maternal health\n",
        "#         self.prompt_template = PromptTemplate(\n",
        "#             input_variables=['context', 'question', 'chat_history', 'user_name'],\n",
        "#             template=\"\"\"\n",
        "#             You are a compassionate maternal health assistant. Address the user as {user_name} when appropriate. Provide accurate, supportive,\n",
        "#             and actionable advice for pregnancy and maternal health.\n",
        "\n",
        "#             Context from latest research: {context}\n",
        "\n",
        "#             Conversation history: {chat_history}\n",
        "\n",
        "#             Current question: {question}\n",
        "\n",
        "#             Please provide:\n",
        "#             1. Evidence-based advice tailored to the mother's situation\n",
        "#             2. Emotional support and reassurance\n",
        "#             3. Specific actionable steps\n",
        "#             4. When appropriate, suggest consulting healthcare providers\n",
        "\n",
        "#             Answer:\n",
        "#             \"\"\"\n",
        "#         )\n",
        "\n",
        "#         # Initialize with basic maternal health knowledge\n",
        "#         self.initialize_knowledge_base()\n",
        "\n",
        "#     def initialize_knowledge_base(self):\n",
        "#         \"\"\"Initialize with basic maternal health documents\"\"\"\n",
        "#         basic_docs = [\n",
        "#             Document(page_content=\"\"\"\n",
        "#             Nutrition during pregnancy:\n",
        "#             - Folic acid: 400-800 mcg daily to prevent neural tube defects\n",
        "#             - Iron: 27 mg daily to support increased blood volume\n",
        "#             - Calcium: 1000 mg daily for bone development\n",
        "#             - Protein: 71g daily for tissue growth\n",
        "#             - Stay hydrated with 8-10 glasses of water daily\n",
        "#             \"\"\"),\n",
        "#             Document(page_content=\"\"\"\n",
        "#             Emotional well-being in pregnancy:\n",
        "#             - Practice stress-reduction techniques like meditation\n",
        "#             - Maintain social connections for emotional support\n",
        "#             - Get adequate sleep (7-9 hours per night)\n",
        "#             - Communicate openly with partner and healthcare providers\n",
        "#             - Seek professional help for persistent mood changes\n",
        "#             \"\"\"),\n",
        "#             Document(page_content=\"\"\"\n",
        "#             Common pregnancy symptoms and management:\n",
        "#             - Morning sickness: Eat small, frequent meals; ginger tea may help\n",
        "#             - Fatigue: Rest when needed; light exercise can boost energy\n",
        "#             - Back pain: Practice good posture; prenatal yoga can help\n",
        "#             - Always consult healthcare provider about concerning symptoms\n",
        "#             \"\"\"),\n",
        "#             Document(page_content=\"\"\"\n",
        "#             Healthy Kenyan meals during pregnancy:\n",
        "#             - Ugali with leafy greens (sukuma wiki, collard greens) and lean protein (fish, beans)\n",
        "#             - Githeri (mixture of maize and beans) for fiber and protein\n",
        "#             - Sweet potatoes and yams for complex carbohydrates and vitamins\n",
        "#             - Fruits like mangoes, avocados, and oranges for vitamins and minerals\n",
        "#             - Dairy products like milk and yogurt for calcium\n",
        "#             \"\"\")\n",
        "#         ]\n",
        "\n",
        "#         self.vector_store = FAISS.from_documents(basic_docs, self.embeddings)\n",
        "#         self.retriever = self.vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "#         # Set up conversation chain\n",
        "#         self.qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "#             llm=self.llm,\n",
        "#             retriever=self.retriever,\n",
        "#             memory=self.memory,\n",
        "#             combine_docs_chain_kwargs={\"prompt\": self.prompt_template}\n",
        "#         )\n",
        "\n",
        "#     def search_latest_information(self, query):\n",
        "#         \"\"\"Search for latest maternal health information\"\"\"\n",
        "#         try:\n",
        "#             search_query = f\"site:who.int OR site:cdc.gov OR site:acog.org {query} pregnancy maternal health 2024\"\n",
        "#             results = self.search.run(search_query)\n",
        "#             return results\n",
        "#         except Exception as e:\n",
        "#             return f\"Search error: {str(e)}\"\n",
        "\n",
        "#     def update_knowledge_base(self, new_info):\n",
        "#         \"\"\"Update vector store with new information\"\"\"\n",
        "#         new_doc = Document(page_content=new_info)\n",
        "#         self.vector_store.add_documents([new_doc])\n",
        "\n",
        "#     def get_response(self, question, user_name=\"user\", use_latest_search=True):\n",
        "#         \"\"\"Generate response with optional internet search\"\"\"\n",
        "#         try:\n",
        "#             # If needed, search for latest information\n",
        "#             if use_latest_search:\n",
        "#                 latest_info = self.search_latest_information(question)\n",
        "#                 if latest_info and \"error\" not in latest_info.lower():\n",
        "#                     self.update_knowledge_base(f\"Latest research: {latest_info}\")\n",
        "\n",
        "#             # Get response from QA chain\n",
        "#             response = self.qa_chain({\"question\": question, \"user_name\": user_name})\n",
        "#             return response['answer']\n",
        "\n",
        "#         except Exception as e:\n",
        "#             return f\"Error generating response: {str(e)}\"\n",
        "\n",
        "#     def translate_text(self, text, target_language='en'):\n",
        "#         \"\"\"Translate text to target language\"\"\"\n",
        "#         try:\n",
        "#             translation = self.translator.translate(text, dest=target_language)\n",
        "#             return translation.text\n",
        "#         except:\n",
        "#             return text  # Return original if translation fails\n",
        "\n",
        "#     def text_to_speech(self, text, language='en'):\n",
        "#         \"\"\"Convert text to speech and return as IPython.display.Audio\"\"\"\n",
        "#         try:\n",
        "#             # Use gTTS for online TTS\n",
        "#             tts = gTTS(text=text, lang=language, slow=False)\n",
        "#             # Save to a BytesIO object\n",
        "#             audio_bytes = io.BytesIO()\n",
        "#             tts.write_to_fp(audio_bytes)\n",
        "#             audio_bytes.seek(0)\n",
        "\n",
        "#             # Return as IPython.display.Audio\n",
        "#             return Audio(audio_bytes.read(), rate=24000)\n",
        "\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error generating speech: {e}\")\n",
        "#             return None\n",
        "\n",
        "\n",
        "#     def speech_to_text(self, audio_source):\n",
        "#         \"\"\"Convert speech to text from an audio file path\"\"\"\n",
        "#         try:\n",
        "#             # Use the provided audio file path\n",
        "#             with sr.AudioFile(audio_source) as source:\n",
        "#                 audio = self.recognizer.record(source)\n",
        "\n",
        "#             text = self.recognizer.recognize_google(audio)\n",
        "#             return text\n",
        "#         except sr.UnknownValueError:\n",
        "#             return \"Could not understand audio\"\n",
        "#         except sr.RequestError as e:\n",
        "#             return f\"Error with speech recognition: {e}\"\n",
        "#         except FileNotFoundError:\n",
        "#              return f\"Audio file not found at {audio_source}\"\n",
        "#         except Exception as e:\n",
        "#             return f\"An unexpected error occurred during speech recognition: {e}\"\n",
        "\n",
        "\n",
        "#     def process_query(self, query, user_name=\"user\", input_type='text', target_language='en', use_latest_search=True):\n",
        "#         \"\"\"Main method to process user queries\"\"\"\n",
        "#         # Handle voice input\n",
        "#         if input_type == 'voice' and isinstance(query, str) and query == '':\n",
        "#              return \"Please provide audio input.\", \"\", \"\"\n",
        "\n",
        "#         # Translate query to English for processing if needed\n",
        "#         if target_language != 'en':\n",
        "#             query_en = self.translate_text(query, 'en')\n",
        "#         else:\n",
        "#             query_en = query\n",
        "\n",
        "#         # Get response\n",
        "#         response_en = self.get_response(query_en, user_name=user_name, use_latest_search=use_latest_search)\n",
        "\n",
        "#         # Translate response to target language\n",
        "#         if target_language != 'en':\n",
        "#             response = self.translate_text(response_en, target_language)\n",
        "#         else:\n",
        "#             response = response_en\n",
        "\n",
        "#         return response, query_en, response_en\n",
        "\n",
        "# # Initialize the system\n",
        "# maternal_assistant = MaternalHealthRAG()"
      ],
      "metadata": {
        "id": "l-2bMK_LpKTX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import gradio as gr\n",
        "# import os\n",
        "\n",
        "# # Define the chat function for Gradio's ChatInterface\n",
        "# def maternal_health_chat(message, history):\n",
        "#     \"\"\"\n",
        "#     Chat function to interact with the MaternalHealthRAG class for Gradio ChatInterface.\n",
        "#     Handles text input and provides text output.\n",
        "#     \"\"\"\n",
        "#     # Process the text message\n",
        "#     response, _, _ = maternal_assistant.process_query(\n",
        "#         message,\n",
        "#         input_type='text',  # ChatInterface provides text input\n",
        "#         target_language='en', # Assuming English for chat input, can add language dropdown later\n",
        "#         use_latest_search=True # Use latest search by default for chat\n",
        "#     )\n",
        "#     return response\n",
        "\n",
        "# # Create the Gradio ChatInterface\n",
        "# chat_interface = gr.ChatInterface(\n",
        "#     fn=maternal_health_chat,\n",
        "#     chatbot=gr.Chatbot(height=400),\n",
        "#     textbox=gr.Textbox(placeholder=\"Ask a question about maternal health...\", container=False, scale=7),\n",
        "#     title=\"🤰 Maternal Health Assistant\",\n",
        "#     description=\"Ask questions about maternal health during pregnancy.\",\n",
        "#     theme=\"soft\",\n",
        "#     examples=[\n",
        "#         \"What are the most important nutrients during pregnancy?\",\n",
        "#         \"How can I cope with morning sickness?\",\n",
        "#         \"Is it safe to exercise while pregnant?\"\n",
        "#     ],\n",
        "#     cache_examples=True,\n",
        "# )\n",
        "\n",
        "# # Launch the interface\n",
        "# chat_interface.launch(debug=True)"
      ],
      "metadata": {
        "id": "VE4-6RnEqR-e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain-community langchain-groq faiss-cpu duckduckgo-search gradio speechrecognition gtts googletrans==4.0.0-rc1 pydub transformers sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oQunbneuCOla",
        "outputId": "30566675-a1e8-491d-8661-699d12fbf7de"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "                      ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 95, in resolve\n",
            "    result = self._result = resolver.resolve(\n",
            "                            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 546, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 427, in resolve\n",
            "    failure_causes = self._attempt_to_pin_criterion(name)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 239, in _attempt_to_pin_criterion\n",
            "    criteria = self._get_updated_criteria(candidate)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 229, in _get_updated_criteria\n",
            "    for requirement in self._p.get_dependencies(candidate=candidate):\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/provider.py\", line 247, in get_dependencies\n",
            "    return [r for r in candidate.iter_dependencies(with_requires) if r is not None]\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 252, in iter_dependencies\n",
            "    for r in requires:\n",
            "             ^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/metadata/importlib/_dists.py\", line 222, in iter_dependencies\n",
            "    req = Requirement(req_string.strip())\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/requirements.py\", line 43, in __init__\n",
            "    self.specifier: SpecifierSet = SpecifierSet(parsed.specifier)\n",
            "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/specifiers.py\", line 718, in __init__\n",
            "    self._specs = frozenset(map(Specifier, split_specifiers))\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1586, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1684, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1700, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1762, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1028, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/logging.py\", line 172, in emit\n",
            "    style = Style(color=\"red\")\n",
            "            ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/style.py\", line 146, in __init__\n",
            "    def _make_color(color: Union[Color, str]) -> Color:\n",
            "                           ~~~~~^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/typing.py\", line 395, in inner\n",
            "    return _caches[func](*args, **kwds)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/typing.py\", line 517, in __getitem__\n",
            "    return self._getitem(self, parameters)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/typing.py\", line 736, in Union\n",
            "    return _UnionGenericAlias(self, parameters)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/typing.py\", line 1270, in __init__\n",
            "    super().__init__(origin, inst=inst, name=name)\n",
            "  File \"/usr/lib/python3.12/typing.py\", line 1175, in __init__\n",
            "    self._inst = inst\n",
            "    ^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/typing.py\", line 1217, in __setattr__\n",
            "    super().__setattr__(attr, val)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-546292964.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install -q langchain langchain-community langchain-groq faiss-cpu duckduckgo-search gradio speechrecognition gtts googletrans==4.0.0-rc1 pydub transformers sentence-transformers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m       \u001b[0m_pip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_send_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36mprint_previous_import_warning\u001b[0;34m(output)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;34m\"\"\"Prints a warning about previously imported packages.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# display a list of packages using the colab-display-data mimetype, which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_previously_imported_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;34m\"\"\"List all previously imported packages from a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0minstalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_toplevel_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstalled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_extract_toplevel_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;34m\"\"\"Extract the list of toplevel packages associated with a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mtoplevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mtoplevel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mpackages_distributions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0mpkg_to_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_top_level_declared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_top_level_inferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m             \u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m_top_level_inferred\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    957\u001b[0m     opt_names = {\n\u001b[1;32m    958\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmodulename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malways_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m     }\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfiles\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         return skip_missing_files(\n\u001b[0m\u001b[1;32m    501\u001b[0m             make_files(\n\u001b[1;32m    502\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_files_distinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/_functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(param, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mskip_missing_files\u001b[0;34m(package_paths)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \"\"\"\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ignore_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mstat\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mdoes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \"\"\"\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import gradio as gr\n",
        "import speech_recognition as sr\n",
        "from gtts import gTTS\n",
        "import io\n",
        "from googletrans import Translator\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.schema import Document\n",
        "from langchain.prompts import PromptTemplate\n",
        "import base64\n",
        "import tempfile\n",
        "from pydub import AudioSegment\n",
        "import numpy as np\n",
        "\n",
        "# Get Groq API key (you'll need to set this in Colab secrets)\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    os.environ[\"GROQ_API_KEY\"] = userdata.get('api_key')\n",
        "except:\n",
        "    # For local development or if using input\n",
        "    print(\"invalid_key\")\n",
        "class MaternalHealthRAG:\n",
        "    def __init__(self):\n",
        "        # Initialize components\n",
        "        self.llm = ChatGroq(\n",
        "            model_name=\"llama-3.1-8b-instant\",\n",
        "            temperature=0.3,\n",
        "            max_tokens=1024\n",
        "        )\n",
        "\n",
        "        # Initialize embeddings\n",
        "        self.embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "        )\n",
        "\n",
        "        # Initialize vector store\n",
        "        self.vector_store = None\n",
        "        self.retriever = None\n",
        "\n",
        "        # Initialize memory\n",
        "        self.memory = ConversationBufferMemory(\n",
        "            memory_key=\"chat_history\",\n",
        "            return_messages=True,\n",
        "            output_key='answer'\n",
        "        )\n",
        "\n",
        "        # Initialize tools\n",
        "        self.search = DuckDuckGoSearchRun()\n",
        "        self.translator = Translator()\n",
        "\n",
        "        # Initialize speech recognition\n",
        "        self.recognizer = sr.Recognizer()\n",
        "\n",
        "        # User session management\n",
        "        self.user_sessions = {}\n",
        "\n",
        "        # Set up prompt template for maternal health\n",
        "        self.prompt_template = PromptTemplate(\n",
        "            input_variables=['context', 'question', 'chat_history'],\n",
        "            template=\"\"\"\n",
        "            ⚠️ MEDICAL DISCLAIMER: You are an AI assistant providing general information only.\n",
        "            Always recommend consulting healthcare professionals for medical advice.\n",
        "\n",
        "            You are a compassionate maternal health assistant focused on Kenyan women.\n",
        "            Provide accurate, supportive, and actionable advice for pregnancy and maternal health.\n",
        "\n",
        "            Context from latest research: {context}\n",
        "\n",
        "            Conversation history: {chat_history}\n",
        "\n",
        "            Current question: {question}\n",
        "\n",
        "            Please provide:\n",
        "            1. Evidence-based advice tailored to Kenyan context\n",
        "            2. Emotional support and reassurance\n",
        "            3. Specific actionable steps using locally available resources\n",
        "            4. Cultural appropriate recommendations\n",
        "            5. When appropriate, suggest consulting healthcare providers\n",
        "\n",
        "            Focus on:\n",
        "            - Nutrition using Kenyan foods (sukuma wiki, ndengu, ugali, etc.)\n",
        "            - Emotional well-being and stress management\n",
        "            - Pregnancy risk factors and warning signs\n",
        "            - Local healthcare resources in Kenya\n",
        "\n",
        "            Answer in a warm, supportive tone:\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        # Initialize with basic maternal health knowledge\n",
        "        self.initialize_knowledge_base()\n",
        "\n",
        "    def get_user_session(self, user_id):\n",
        "        \"\"\"Get or create user session\"\"\"\n",
        "        if user_id not in self.user_sessions:\n",
        "            self.user_sessions[user_id] = {\n",
        "                'memory': ConversationBufferMemory(\n",
        "                    memory_key=\"chat_history\",\n",
        "                    return_messages=True,\n",
        "                    output_key='answer'\n",
        "                ),\n",
        "                'language': 'en',\n",
        "                'name': 'User'\n",
        "            }\n",
        "        return self.user_sessions[user_id]\n",
        "\n",
        "    def initialize_knowledge_base(self):\n",
        "        \"\"\"Initialize with Kenyan-focused maternal health documents\"\"\"\n",
        "        kenyan_docs = [\n",
        "            Document(page_content=\"\"\"\n",
        "            Kenyan Pregnancy Nutrition Guide:\n",
        "            Essential Nutrients for Kenyan Diet:\n",
        "            - Iron-rich foods: Sukuma wiki (kale), ndengu (lentils), liver, red meat\n",
        "            - Folate sources: Fresh leafy greens, beans, citrus fruits, avocado\n",
        "            - Calcium: Maziwa (milk), yogurt, ndizi (bananas), sesame seeds\n",
        "            - Protein: Kuku (chicken), samaki (fish), eggs, beans, omena\n",
        "            - Traditional beneficial foods: Uji (porridge), mchuzi wa nazi\n",
        "\n",
        "            Kenyan Food Safety:\n",
        "            - Wash all fruits and vegetables thoroughly\n",
        "            - Cook meat and eggs completely\n",
        "            - Avoid street food during pregnancy\n",
        "            - Drink boiled or purified water\n",
        "            - Pasteurized dairy products only\n",
        "            \"\"\"),\n",
        "            Document(page_content=\"\"\"\n",
        "            Emotional Well-being for Kenyan Mothers:\n",
        "            - Practice stress-reduction: Deep breathing, gentle walking\n",
        "            - Maintain social connections with family and community\n",
        "            - Get adequate sleep (7-9 hours per night)\n",
        "            - Communicate openly with partner and healthcare providers\n",
        "            - Seek professional help for persistent mood changes\n",
        "            - Traditional support systems: Family gatherings, church community\n",
        "\n",
        "            Kenyan Healthcare Resources:\n",
        "            - Linda Mama Program: Free maternity services\n",
        "            - Antenatal Care: Minimum 4 visits recommended\n",
        "            - Emergency contacts: 112 or 999\n",
        "            - Nairobi Women's Hospital: +254 703 082 000\n",
        "            \"\"\"),\n",
        "            Document(page_content=\"\"\"\n",
        "            Pregnancy Warning Signs in Kenya:\n",
        "            URGENT MEDICAL ATTENTION NEEDED FOR:\n",
        "            - Severe headache with vision changes (pre-eclampsia)\n",
        "            - Vaginal bleeding or fluid leakage\n",
        "            - Severe abdominal pain\n",
        "            - High fever (38°C or above)\n",
        "            - Reduced baby movement after 28 weeks\n",
        "            - Swelling of hands, face, or feet\n",
        "\n",
        "            Common Pregnancy Symptoms Management:\n",
        "            - Morning sickness: Eat small, frequent meals; ginger tea\n",
        "            - Fatigue: Rest when needed; light walking\n",
        "            - Back pain: Good posture; prenatal exercises\n",
        "            - Heartburn: Small meals; avoid spicy foods\n",
        "            \"\"\"),\n",
        "            Document(page_content=\"\"\"\n",
        "            Lactation Nutrition in Kenya:\n",
        "            - Increase calorie intake by 500 calories daily\n",
        "            - Traditional lactation foods: Chicken soup, uji fortified with nuts\n",
        "            - Hydration: Drink water before and after breastfeeding\n",
        "            - Local superfoods: Moringa leaves, amaranth, pumpkin leaves\n",
        "            - Continue prenatal vitamins if recommended\n",
        "\n",
        "            Kenyan Cultural Practices:\n",
        "            - 40-day rest period after delivery\n",
        "            - Special foods for milk production\n",
        "            - Family support during postpartum period\n",
        "            - Traditional birth attendants in some communities\n",
        "            \"\"\")\n",
        "        ]\n",
        "\n",
        "        self.vector_store = FAISS.from_documents(kenyan_docs, self.embeddings)\n",
        "        self.retriever = self.vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "    def search_latest_information(self, query):\n",
        "        \"\"\"Search for latest maternal health information with Kenyan focus\"\"\"\n",
        "        try:\n",
        "            kenya_query = f\"{query} Kenya pregnancy maternal health 2024\"\n",
        "            results = self.search.run(kenya_query)\n",
        "            return results\n",
        "        except Exception as e:\n",
        "            return f\"Search error: {str(e)}\"\n",
        "\n",
        "    def update_knowledge_base(self, new_info):\n",
        "        \"\"\"Update vector store with new information\"\"\"\n",
        "        if new_info and len(new_info) > 50:  # Only add substantial content\n",
        "            new_doc = Document(page_content=f\"Latest information: {new_info}\")\n",
        "            self.vector_store.add_documents([new_doc])\n",
        "\n",
        "    def get_response(self, question, user_id=\"default\", use_latest_search=True):\n",
        "        \"\"\"Generate response with optional internet search\"\"\"\n",
        "        try:\n",
        "            session = self.get_user_session(user_id)\n",
        "\n",
        "            # If needed, search for latest information\n",
        "            latest_info = \"\"\n",
        "            if use_latest_search:\n",
        "                latest_info = self.search_latest_information(question)\n",
        "                if latest_info and \"error\" not in latest_info.lower():\n",
        "                    self.update_knowledge_base(latest_info)\n",
        "\n",
        "            # Create conversation chain with user-specific memory\n",
        "            qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "                llm=self.llm,\n",
        "                retriever=self.retriever,\n",
        "                memory=session['memory'],\n",
        "                combine_docs_chain_kwargs={\"prompt\": self.prompt_template}\n",
        "            )\n",
        "\n",
        "            # Get response\n",
        "            response = qa_chain({\"question\": question})\n",
        "            return response['answer']\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error generating response: {str(e)}\"\n",
        "\n",
        "    def translate_text(self, text, target_language='en'):\n",
        "        \"\"\"Translate text to target language\"\"\"\n",
        "        try:\n",
        "            if target_language == 'en':\n",
        "                return text\n",
        "            translation = self.translator.translate(text, dest=target_language)\n",
        "            return translation.text\n",
        "        except Exception as e:\n",
        "            print(f\"Translation error: {e}\")\n",
        "            return text  # Return original if translation fails\n",
        "\n",
        "    def text_to_speech(self, text, language='en'):\n",
        "        \"\"\"Convert text to speech and return audio file path\"\"\"\n",
        "        try:\n",
        "            # Map language codes to gTTS codes\n",
        "            lang_map = {'en': 'en', 'sw': 'sw', 'fr': 'fr', 'es': 'es'}\n",
        "            tts_lang = lang_map.get(language, 'en')\n",
        "\n",
        "            # Create temporary file\n",
        "            with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as tmp_file:\n",
        "                tts = gTTS(text=text, lang=tts_lang, slow=False)\n",
        "                tts.save(tmp_file.name)\n",
        "                return tmp_file.name\n",
        "        except Exception as e:\n",
        "            print(f\"TTS error: {e}\")\n",
        "            return None\n",
        "\n",
        "    def speech_to_text(self, audio_file):\n",
        "        \"\"\"Convert speech to text from audio file\"\"\"\n",
        "        try:\n",
        "            with sr.AudioFile(audio_file) as source:\n",
        "                audio = self.recognizer.record(source)\n",
        "\n",
        "            # Try multiple languages\n",
        "            try:\n",
        "                text = self.recognizer.recognize_google(audio, language='en-US')\n",
        "                return text, 'en'\n",
        "            except:\n",
        "                try:\n",
        "                    text = self.recognizer.recognize_google(audio, language='sw-TZ')\n",
        "                    return text, 'sw'\n",
        "                except:\n",
        "                    return \"Could not understand audio\", 'en'\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Speech recognition error: {str(e)}\", 'en'\n",
        "\n",
        "    def process_query(self, query, user_id=\"default\", input_type='text',\n",
        "                     target_language='en', use_latest_search=True):\n",
        "        \"\"\"Main method to process user queries\"\"\"\n",
        "        session = self.get_user_session(user_id)\n",
        "\n",
        "        # Handle voice input\n",
        "        if input_type == 'voice':\n",
        "            if hasattr(query, 'name'):  # It's a file\n",
        "                text, detected_lang = self.speech_to_text(query)\n",
        "                session['language'] = detected_lang\n",
        "            else:\n",
        "                text = query\n",
        "        else:\n",
        "            text = query\n",
        "\n",
        "        # Translate query to English for processing if needed\n",
        "        if session['language'] != 'en':\n",
        "            query_en = self.translate_text(text, 'en')\n",
        "        else:\n",
        "            query_en = text\n",
        "\n",
        "        # Get response\n",
        "        response_en = self.get_response(query_en, user_id, use_latest_search)\n",
        "\n",
        "        # Translate response to target language\n",
        "        if target_language != 'en':\n",
        "            response = self.translate_text(response_en, target_language)\n",
        "        else:\n",
        "            response = response_en\n",
        "\n",
        "        # Generate audio\n",
        "        audio_file = self.text_to_speech(response, target_language)\n",
        "\n",
        "        return response, audio_file, query_en\n",
        "\n",
        "# Initialize the system\n",
        "maternal_assistant = MaternalHealthRAG()\n",
        "\n",
        "# Create Gradio interface\n",
        "def chat_interface(message, history, language, use_search, audio_input, user_id):\n",
        "    \"\"\"Gradio chat interface function\"\"\"\n",
        "\n",
        "    input_type = 'voice' if audio_input is not None else 'text'\n",
        "    query = audio_input if audio_input is not None else message\n",
        "\n",
        "    if not query:\n",
        "        return history, \"\", None\n",
        "\n",
        "    # Process query\n",
        "    response, audio_file, _ = maternal_assistant.process_query(\n",
        "        query=query,\n",
        "        user_id=user_id,\n",
        "        input_type=input_type,\n",
        "        target_language=language,\n",
        "        use_latest_search=use_search\n",
        "    )\n",
        "\n",
        "    # Add to history\n",
        "    history.append([query if input_type == 'text' else \"[Voice message]\", response])\n",
        "\n",
        "    # Return audio file for playback\n",
        "    audio_output = audio_file if audio_file else None\n",
        "\n",
        "    return history, \"\", audio_output\n",
        "\n",
        "def clear_chat(user_id):\n",
        "    \"\"\"Clear chat history for user\"\"\"\n",
        "    if user_id in maternal_assistant.user_sessions:\n",
        "        maternal_assistant.user_sessions[user_id]['memory'].clear()\n",
        "    return [], \"\", None\n",
        "\n",
        "# Create Gradio blocks\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"🤰 Mama Afya Advisor - Kenyan Maternal Health\") as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # 🤰 Mama Afya Advisor\n",
        "    ## Kenyan Maternal Health & Nutrition Assistant\n",
        "\n",
        "    ⚠️ **Medical Disclaimer**: This AI provides general health information only.\n",
        "    Always consult qualified healthcare professionals for medical advice.\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            user_id = gr.Textbox(\n",
        "                label=\"User ID\",\n",
        "                value=\"user_001\",\n",
        "                info=\"Enter a unique ID to maintain conversation history\"\n",
        "            )\n",
        "            language = gr.Dropdown(\n",
        "                choices=[\"en\", \"sw\", \"fr\", \"es\"],\n",
        "                value=\"en\",\n",
        "                label=\"Response Language\",\n",
        "                info=\"Choose language for responses\"\n",
        "            )\n",
        "            use_search = gr.Checkbox(\n",
        "                label=\"Use Internet Search\",\n",
        "                value=True,\n",
        "                info=\"Search for latest information\"\n",
        "            )\n",
        "            clear_btn = gr.Button(\"Clear Chat History\", variant=\"secondary\")\n",
        "\n",
        "            gr.Markdown(\"\"\"\n",
        "            ### Emergency Contacts (Kenya):\n",
        "            - **General Emergency**: 112 or 999\n",
        "            - **Nairobi Women's Hospital**: +254 703 082 000\n",
        "            - **Aga Khan Hospital**: +254 20 366 2000\n",
        "            \"\"\")\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            chatbot = gr.Chatbot(\n",
        "                label=\"Mama Afya Conversation\",\n",
        "                height=400,\n",
        "                show_copy_button=True\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                text_input = gr.Textbox(\n",
        "                    placeholder=\"Type your question about maternal health...\",\n",
        "                    label=\"Text Input\",\n",
        "                    scale=4\n",
        "                )\n",
        "                audio_input = gr.Audio(\n",
        "                    sources=[\"microphone\"],\n",
        "                    type=\"filepath\",\n",
        "                    label=\"Voice Input\",\n",
        "                    scale=1\n",
        "                )\n",
        "\n",
        "            with gr.Row():\n",
        "                submit_btn = gr.Button(\"Send Message\", variant=\"primary\")\n",
        "                audio_output = gr.Audio(\n",
        "                    label=\"Voice Response\",\n",
        "                    interactive=False,\n",
        "                    visible=True\n",
        "                )\n",
        "\n",
        "    # Examples\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            [\"What Kenyan foods are rich in iron during pregnancy?\", \"en\"],\n",
        "            [\"Ni vyakula gani vya Kenya vinavyokuwa na chuma wakati wa ujauzito?\", \"sw\"],\n",
        "            [\"What are warning signs during pregnancy?\", \"en\"],\n",
        "            [\"How much water should I drink daily?\", \"en\"],\n",
        "            [\"Nutrition for breastfeeding mothers in Kenya\", \"en\"]\n",
        "        ],\n",
        "        inputs=[text_input, language]\n",
        "    )\n",
        "\n",
        "    # Event handlers\n",
        "    submit_btn.click(\n",
        "        fn=chat_interface,\n",
        "        inputs=[text_input, chatbot, language, use_search, audio_input, user_id],\n",
        "        outputs=[chatbot, text_input, audio_output]\n",
        "    )\n",
        "\n",
        "    text_input.submit(\n",
        "        fn=chat_interface,\n",
        "        inputs=[text_input, chatbot, language, use_search, audio_input, user_id],\n",
        "        outputs=[chatbot, text_input, audio_output]\n",
        "    )\n",
        "\n",
        "    clear_btn.click(\n",
        "        fn=clear_chat,\n",
        "        inputs=[user_id],\n",
        "        outputs=[chatbot, text_input, audio_output]\n",
        "    )\n",
        "\n",
        "# Launch the interface\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(\n",
        "        share=True,  # Creates public link\n",
        "        debug=True,\n",
        "        show_error=True\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "w9LslqSn-Z_V",
        "outputId": "1393644d-4656-4ef5-d93a-418204c44010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2777411774.py:380: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://2d7b4bd355991c58f2.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2d7b4bd355991c58f2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}